Nobody reported video of New Zealand mosque massacre until 29 minutes after it was posted, Facebook says
   It took nearly half an hour for someone to report live-streamed video of the massacre inside a New Zealand mosque, which was viewed thousands of times on Facebook before it was later removed from the platform. 
   Social media and video-sharing sites have faced backlash over its response to the clip, recorded from the perspective of the shooter as he gunned down 41 worshipers gathered for Friday prayer at the Al Noor mosque in Christchurch. 
   From there, authorities said the gunman drove three miles away and opened fire inside a mosque in Linwood, where seven more people were killed. Another two people struck by gunfire also later died at area hospitals. 
   Facebook in a statement Monday said video of the attack was viewed less than 200 times and was not once reported during the live broadcast. 
   It wasn’t until 12 minutes after the livestream ended – and 29 minutes after it was first shared – that a user reported it to Facebook. 
   By the time it was removed, the massacre video had been viewed about 4,000 times on the social media site, according to Chris Sonderby, the company’s vice president and deputy general counsel. 
   Sonderby said the clip was immediately flagged as a terror attack, meaning “that any praise, support and representation of the events violates our community standards and is not permitted on the platform." The shooting suspect’s personal accounts were also wiped from Facebook and Instagram. 
   But before Facebook even learned of the livestream, it was uploaded at least once to the video and image-sharing platform 8chan, Sonderby noted. From there, Facebook was forced to reckon with copies of the clips cropping up on the site. 
   “We removed the original Facebook Live video and hashed it so that other shares that are visually similar to that video are then detected and automatically removed from Facebook and Instagram,” Sonderby said. 
   “Some variants such as screen recordings were more difficult to detect, so we expanded to additional detection systems including the use of audio technology.” 
   In the first 24 hours, Facebook took down nearly 1.5 million videos of the attack, posted by users all over the globe. Another 1.2 million similar videos were flagged in the upload process “and prevented from being seen on our services,” according to Facebook’s statement. 
   Still, New Zealand Prime Minister Jacinda Ardern has slammed Facebook and other platforms in wake of the mosque massacres, accusing them of doing too little to prevent the spread of the graphic video. 
   “There is no question that ideas and language of division have existed for decades,” Ardern said Tuesday from the Parliament floor. 
   “But the form of distribution, the tools of organization – they are new. We cannot simply sit back and accept that these platforms just exist and that what is said on them is not the responsibility of the place where they are published. They are the publisher, not just the postman. This cannot be a case of all profit and no responsibility.” 
   During the same address to Parliament on Tuesday, Ardern vowed to never say the name of the shooter behind the deadly attacks. 
   “He obviously had a range of reasons for committing this atrocious terrorist attack. Lifting his profile was one of them. And that’s something that we can absolutely deny,” she said, declining to comment on whether she believed the gunman should face trial behind closed doors. 
   “One thing I can assure you – you won’t hear me speak his name,” Ardern added. 
   “I implore you: Speak the names of those who were lost, rather than the name of the man who took them. He may have sought notoriety, but we in New Zealand will give him nothing. Not even his name.”   
