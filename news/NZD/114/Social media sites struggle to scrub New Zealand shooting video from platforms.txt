   It was an uphill battle for social media to scrub a viral video of the horrifying mass shootings at two New Zealand mosques. 
   Sites like YouTube and Facebook scrambled to remove the video live-streamed by Australian white nationalist gunman Brenton Tarrant on Friday during the rampage in Christchurch that killed 50 worshipers. 
   "Our hearts are broken over today’s terrible tragedy in New Zealand," YouTube tweeted. "Please know we are working vigilantly to remove any violent footage." 
   Both sites have zero-tolerance policies for videos showing graphic violence. But as soon as they took the video down, it popped up elsewhere as users re-posted the shocking video. 
   “There will always be a faction of the web that pushes against the grain of acceptable behavior and content,” tech ethicist David Ryan Polgar told the Daily News. “Banned content, unfortunately, also attracts some users because of the very fact that it is taboo. If you tell people you can't see what is behind the curtain, that also makes some people more interested in seeing what is behind the curtain.” 
   Polgar explained it’s “very difficult to eliminate” content that’s gone viral. 
   “It is as if the platforms are spending a great deal of time putting out the proverbial fire, as opposed to stopping fires from happening in the first place,” he said. 
   Even Amazon isn’t free from trafficking in potentially dangerous content. A book about the QAnon conspiracy is one of its best-sellers. 
   Some users reported seeing the video autoplay on their Twitter feeds, leading to a spike in Google searches for “disable autoplay,” a feature that forces users to manually play videos and also saves mobile data. 
   Protests cropped up outside tech company headquarters Friday. But the backlash against tech companies was more direct online. 
   “Hi are you doing anything to get video of a horrific mass shooting off your website @jack,” television writer Kara Brown wrote in a tweet addressed to Twitter CEO and co-founder Jack Dorsey. 
   “Lives were lost, more will be,” tweeted software engineer Jackie Luo. “YouTube is complicit.” 
   The 1996 Communications Decency Act says in part that online platforms that host speech are not responsible or liable for the content of that speech, but Polgar thinks 2019 could be the year that section of the law gets tightened up. 
   “This feels like a watershed moment for social media, as citizens start applying pressure for companies to change the status quo,” he said. “People are going to start wondering why our legislative branch has been asleep at the wheel throughout the inception and massive growth of social media.” 
   Reddit banned two of its channels on Friday in response to the shooting. Visitors to R/WatchPeopleDie and R/Gore received the message that the subs had been “banned from Reddit.” 
   "Any content containing links to the video stream are being removed in accordance with our site-wide policy," Reddit said in a statement. 
   Prior to the ban, the video had been posted on R/WatchPeopleDie. 
   “Hopefully Reddit believes in letting you decide for yourself whether or not you want to see unfiltered reality,” a moderator wrote. 
   YouTube initially put a disclaimer on the video that gave users the option to watch it. Twitter’s response team took several hours to respond to takedown requests. By Friday afternoon, Facebook, Twitter, and YouTube had scrubbed nearly every version of the video. 
   Facebook said in a statement that Tarrant’s accounts on Facebook and Instagram had been removed. 
   Facebook added it was “removing any praise or support for the crime and the shooter as soon as we’re aware.” 
   Police in Christchurch asked people not to share the video and flag it if they see it. 
   "We would strongly urge that the link not be shared. We are working to have any footage removed," the New Zealand police said. 
