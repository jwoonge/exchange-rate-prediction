France Will Debate a Bill to Stop Online Hate Speech. What’s at Stake?
PARIS — The French Parliament will start debating a bill on online hate speech and harassment on Wednesday, as countries around the world grapple with the question of what content is acceptable online and how to regulate huge technological platforms with a global reach. 
In France, laws regulating free speech are generally more restrictive than in the United States, and rules against violence or hate speech already exist. 
But the authorities say that the law needs to catch up with tech platforms. In an op-ed published this month in the newspaper Le Monde, a group of government ministers said that while social networks had created a “new horizon for socializing and exchanging,” they had also shown humanity’s “darkest sides.”
Here is what you need to know about the proposal. 
President Emmanuel Macron announced the bill in February at a meeting of an umbrella group of Jewish organizations. Mr. Macron, who was addressing the group amid a resurgence of anti-Semitism around Europe, said that there was a need for “incisive, concrete” acts against all kinds of hate speech. 
The bill is sponsored by Laetitia Avia, a member of France’s lower house of Parliament and of Mr. Macron’s party, La République en Marche. A former business lawyer who was born in France to parents from Togo, she has been the target of racist taunts and death threats online.
She said that the current rules were instituted before social media platforms like Facebook or Twitter existed and did little to incentivize those platforms to police content. “The idea, clearly, is to put an end to impunity on social networks,” she said in an interview last week with the newsmagazine Le Point. 
She added, “There is no reason that comments that would not be tolerated on a bus, in a cafe or in school — basically, in ‘real life’ — should be tolerated on a website or network.” Public discussion of the bill will start in the National Assembly, the lower house, with a vote the following week. The Senate, France’s upper house of Parliament, will examine the bill next, but a legislative recess over the summer means that the bill may not become law until the fall.
The main goal of the bill is to push tech companies to regulate content more forcefully and to crack down on hate speech more quickly. It is partly inspired by a law recently passed in Germany, where the authorities issued their first fine under the legislation on Tuesday.
The German authorities fined Facebook 2 million euros, about $2.26 million, on the grounds that it failed to disclose information about the full number of hate-speech postings reported in the first half of last year. Facebook, which will have an opportunity to appeal the fine, did not have an immediate comment. 
Under the French bill, once users flag content as hate speech, online platforms would have 24 hours to analyze the information, and, if necessary, remove it. The bill also says that tech companies have to more clearly display a unified option for flagging and reporting such messages. 
The scope of content that platforms would be obliged to remove is broad: any message that attacks someone on the basis of race, religion, sexual orientation, nationality, gender identity or disability; propaganda tied to terrorism or war crimes; and harassment. 
If platforms refuse to remove such content, they could face fines of 1.25 million euros, or about $1.4 million. Company officials could face a year in prison and fines of up to €250,000.
Repeated violations could prompt France’s media watchdog to impose fines of up to 4 percent of the company’s global revenue — meaning, potentially, tens or even hundreds of millions of dollars. 
The bill also creates penalties — a €15,000 fine and up to a year in prison — for individuals who abuse reporting mechanisms. 
Some critics argue that the legislation puts the onus for regulating content solely on online platforms, and that tech companies, unwilling or unable to appreciate the subtleties of regulating speech, will be overzealous in their policing. That will be harmful to free speech, critics say. 
Christophe Bigot, a lawyer who specializes in media-related cases, wrote in an op-ed article for Le Figaro that the removal of content — “in other words, censorship” — would be decided by a private company without the involvement of judges “who are the constitutional guarantors of fundamental freedoms.”
Mr. Bigot pointed to several examples of free-speech issues that tech companies would find difficult to settle in less than 24 hours, such as whether the Boycott, Divestment and Sanctions movement against Israel was anti-Semitic.
“How can one leave that analysis to a simple employee of a platform, even motivated by the best intentions?” Mr. Bigot wrote. “They won’t take the risk of exposing their employer to a penalty equal to 4 percent of its revenue.” 
A better idea, some critics say, would be to put more financial and human resources behind laws that already exist — especially those that penalize the authors of hate speech. Publicly denying the Holocaust, for instance, is a criminal offense, and more recent laws have criminalized speech that supports or justifies terrorism.
Anne-Sophie Choné-Grimaldi, a law professor at the Paris Nanterre University, said in an op-ed article for Le Monde this month that she agreed that hate speech should not be tolerated online any more than it is in public spaces.
“But as far we know, in the street, those who are punished are the people who make insults or any other type of illegal speech, not those who manage the road,” Ms. Choné-Grimaldi wrote.
“Online, it is still too rare for the author of the illegal content that was published to be worried,” she added. “And yet, laws exist that enable the judicial authority to seek the identity of the author of a message when it is unknown, and to inflict heavy penalties.” 
